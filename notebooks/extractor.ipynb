{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to extract small image crops from the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm as tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IndexEntry Objects are used to store all the information regarding a particular bounding box/ bounding box crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IndexEntry = namedtuple('IndexEntry', ['img_path', 'sub_idx', 'classname', 'left', 'top', 'right', 'bottom'], verbose=False)\n",
    "IndexEntryCrop = namedtuple('IndexEntryCrop', ['img_path', 'sub_idx', 'crop_path_1p0', 'classname', 'left', 'top', 'right', 'bottom'], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pickle file contains an list of IndexEntry Objects with the full information of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_file = '/raid/user-data/lscheucher/projects/bounding_box_classifier/full_object_index.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    idxs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the directory where the croped images should be written to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATADIR = '/raid/user-data/lscheucher/tmp/pytorch_classifier_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follwoing function is used to process the huge list of IndexEntry objects in parallel.\n",
    "The index object are stored in a big list names idxs.\n",
    "So to work on parrallel, this function needs a tuple `indices` as argument, specifying which part of the full list an instance of the function should work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallelfun(indices):\n",
    "    sublist= copy.deepcopy(idxs[indices[0]:indices[1]])\n",
    "    idxs_crop = []\n",
    "    i=0\n",
    "    start=time.time()\n",
    "    for entry in sublist:\n",
    "        \n",
    "        img_final = np.zeros(shape=(224,224,3), dtype='uint8')\n",
    "        img = cv2.imread(entry.img_path)\n",
    "        img = img[entry.top:entry.bottom, entry.left:entry.right, :]\n",
    "\n",
    "        H, W, C = img.shape\n",
    "        if H<=224 and W<=224:\n",
    "            img=img\n",
    "\n",
    "        elif H>W:\n",
    "            fac = 224/H\n",
    "            img = cv2.resize(img, (int(W*fac),224))\n",
    "            H, W, C = img.shape\n",
    "        else:#W>H\n",
    "            fac = 224/W           # W    H\n",
    "            img = cv2.resize(img, (224 ,int(H*fac)))\n",
    "            H, W, C = img.shape\n",
    "        dh = (224-H)>>1\n",
    "        dw = (224-W)>>1\n",
    "        img_final[dh:dh+H, dw:dw+W, :] = img\n",
    "        \n",
    "        \n",
    "        if not os.path.isdir(os.path.join(DATADIR,entry.classname)):\n",
    "            os.mkdir(os.path.join(DATADIR,entry.classname))\n",
    "        #crop_path_1p0 = os.path.join(DATADIR,entry.classname,str(i)+'.png')\n",
    "        crop_path_1p0 = entry.img_path.split('/')[-1].split('.')[0]+str(entry.sub_idx)+'.png'\n",
    "        crop_path_1p0 = os.path.join(DATADIR, entry.classname, crop_path_1p0)\n",
    "        cv2.imwrite(crop_path_1p0, img_final)\n",
    "        idxs_crop.append(IndexEntryCrop(img_path=entry.img_path,\n",
    "                                        sub_idx=entry.sub_idx,\n",
    "                                        crop_path_1p0=crop_path_1p0,\n",
    "                                        classname=entry.classname,\n",
    "                                        left=entry.left,\n",
    "                                        top=entry.top,\n",
    "                                        right=entry.right,\n",
    "                                        bottom=entry.bottom))\n",
    "        i += 1\n",
    "        if i%1000==0: print(i)\n",
    "    return idxs_crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `indices` tuples for a number `N` of parallel processes.\n",
    "Store the result in `arg_instances`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 12119\n",
      "1 12119 24238\n",
      "2 24238 36357\n",
      "3 36357 48476\n",
      "4 48476 60595\n",
      "5 60595 72714\n",
      "6 72714 84833\n",
      "7 84833 96952\n",
      "8 96952 109071\n",
      "9 109071 121190\n",
      "10 121190 133309\n",
      "11 133309 145428\n",
      "12 145428 157547\n",
      "13 157547 169666\n",
      "14 169666 181785\n",
      "15 181785 193904\n",
      "16 193904 206023\n",
      "17 206023 218142\n",
      "18 218142 230261\n",
      "19 230261 242380\n",
      "20 242380 254499\n",
      "21 254499 266618\n",
      "22 266618 278737\n",
      "23 278737 290856\n",
      "24 290856 302975\n",
      "25 302975 315094\n",
      "26 315094 327213\n",
      "27 327213 339332\n",
      "28 339332 351451\n",
      "29 351451 363570\n",
      "30 363570 375689\n",
      "31 375689 387808\n",
      "32 387808 399927\n",
      "33 399927 412046\n",
      "34 412046 424165\n",
      "35 424165 436284\n",
      "36 436284 448403\n",
      "37 448403 460522\n",
      "38 460522 472641\n",
      "39 472641 484779\n"
     ]
    }
   ],
   "source": [
    "N=40\n",
    "\n",
    "step = int(len(idxs)/N)\n",
    "arg_instances= []\n",
    "\n",
    "for i in range(N-1):\n",
    "    print(i, i*step, (i+1)*step)\n",
    "    #arg_instances.append(idxs[i*step:(i+1)*step])\n",
    "    arg_instances.append([i*step,(i+1)*step])\n",
    "print(SPLITCOUNT-1,(N-1)*step,len(idxs))\n",
    "arg_instances.append([(N-1)*step, len(idxs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `N` independent processes working on `idxs` in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "4000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "5000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "6000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "7000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "9000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "11000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=SPLITCOUNT, backend=\"multiprocessing\")(\n",
    "             map(delayed(parallelfun), arg_instances))\n",
    "\n",
    "\n",
    "# where arg_instances is list of values for which myfun is computed in parallel.\n",
    "# The main restriction is that myfun must be a toplevel function.\n",
    "# The backend parameter can be either \"threading\" or \"multiprocessing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('tempsave.pickle','wb') as f:\n",
    "#     pickle.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = [j for i in results for j in i]\n",
    "\n",
    "with open('/raid/user-data/lscheucher/projects/bounding_box_classifier/full_object_index_crop.pickle','wb') as f:\n",
    "    pickle.dump(result,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt_new",
   "language": "python",
   "name": "tensorrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
